{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Kcl0YURr1yHO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg9vHsH0pn_U"
   },
   "source": [
    "# Import and Preprocess/Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6aFAYwJFHPwp"
   },
   "outputs": [],
   "source": [
    "# Function which does everything below at once\n",
    "def open_format_data(filename):\n",
    "  # Save data from txt into list\n",
    "  f = open(filename, \"r\")\n",
    "\n",
    "  list_data = []\n",
    "  for x in f:\n",
    "      list_data.append(f.readline().rstrip().split(\"\\t\"))\n",
    "\n",
    "  # Load list into dataframe\n",
    "  column_names = ['label', \"sentence\"]\n",
    "  df = pd.DataFrame(list_data, columns= column_names)\n",
    "  df.head(10)\n",
    "\n",
    "  # Drop any null values\n",
    "  df = df.dropna()\n",
    "\n",
    "  # Drop duplicates\n",
    "  df = df.drop_duplicates()\n",
    "\n",
    "  # Append number representing label as code\n",
    "  df.label = pd.Categorical(df.label)\n",
    "  df['code'] = df.label.cat.codes\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qyP98KpnHvv0"
   },
   "outputs": [],
   "source": [
    "df = open_format_data(\"train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTvVH5UyHsTX"
   },
   "outputs": [],
   "source": [
    "# Save data from txt into list\n",
    "f = open(\"/content/drive/My Drive/Griffith/Data Mining/train.txt\", \"r\")\n",
    "\n",
    "list_data = []\n",
    "for x in f:\n",
    "    list_data.append(f.readline().rstrip().split(\"\\t\"))\n",
    "\n",
    "print(list_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "ddlcuFZy2Sg0",
    "outputId": "e15c2ce5-35e4-4d71-ed85-52e0f4fa361d"
   },
   "outputs": [],
   "source": [
    "# Load list into dataframe\n",
    "column_names = ['label', \"sentence\"]\n",
    "df = pd.DataFrame(list_data, columns= column_names)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "bCrHecKv2T6G",
    "outputId": "82cdc603-84f2-4bfd-85e5-5b32e2e7e8d7"
   },
   "outputs": [],
   "source": [
    "# Count all null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "0tcXakJo2WJA",
    "outputId": "2e2cb3c1-f719-477a-89cf-d08edc5621f7"
   },
   "outputs": [],
   "source": [
    "# Drop any null values\n",
    "df = df.dropna()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "tz6IRB2X2Y1Z",
    "outputId": "be6a0df9-a8e3-4d76-c40f-f21fbed5a1dd"
   },
   "outputs": [],
   "source": [
    "# Detect duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "1CwPAgHx2Z7r",
    "outputId": "7aa74ead-b74c-4048-91e9-58b5e32c6268"
   },
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "TYiU8VB725XV",
    "outputId": "7ca850a4-3cfa-4ebe-f59b-1728132a94a1"
   },
   "outputs": [],
   "source": [
    "# Append number representing label as code\n",
    "df.label = pd.Categorical(df.label)\n",
    "df['code'] = df.label.cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0QiFmEMphvr"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "FiwPvz1bpy91",
    "outputId": "22af54a2-4c23-4801-9700-cbe23b8f9a37"
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "nIadEZxtqNDg",
    "outputId": "9ef35a7c-7ea5-428d-a80c-98059140eebc"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "2EIxdIgOkNiW",
    "outputId": "73d79ed3-a443-43e6-d368-f0b0a139345e"
   },
   "outputs": [],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "wBk2y4aeVnl_",
    "outputId": "8f55898b-2d00-48c9-ab3e-5e29e7c3e75d"
   },
   "outputs": [],
   "source": [
    "df.groupby(\"label\")['sentence'].count().plot.bar()\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ERuUgqEpX0I"
   },
   "source": [
    "# Tensorflow Data Formatting and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "ZtcKaqio4Yb5",
    "outputId": "1c9a94ac-5cbf-43e2-8910-2feafa346f7d"
   },
   "outputs": [],
   "source": [
    "# Load into tensorflow dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((df.sentence, df.code))\n",
    "for b in train_dataset.take(5):\n",
    "  print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "u41AF_t87Hsk",
    "outputId": "224f6c3b-ece9-4121-8f29-36f3a4c6f26c"
   },
   "outputs": [],
   "source": [
    "# Generate vocab\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "vocabulary_set = set()\n",
    "for text_tensor, _ in train_dataset:\n",
    "  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
    "  vocabulary_set.update(some_tokens)\n",
    "\n",
    "vocab_size = len(vocabulary_set)\n",
    "# Increase vocab size for padding value (0)\n",
    "vocab_size += 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4xx2yBD7gTJ"
   },
   "outputs": [],
   "source": [
    "# Setup encoder\n",
    "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)\n",
    "\n",
    "def encode(text_tensor, label):\n",
    "  encoded_text = encoder.encode(text_tensor.numpy())\n",
    "  return encoded_text, label\n",
    "\n",
    "def encode_map_fn(text, label):\n",
    "  # py_func doesn't set the shape of the returned tensors.\n",
    "  encoded_text, label = tf.py_function(encode, \n",
    "                                       inp=[text, label], \n",
    "                                       Tout=(tf.int64, tf.int8))\n",
    "\n",
    "  # `tf.data.Datasets` work best if all components have a shape set\n",
    "  #  so set the shapes manually: \n",
    "  encoded_text.set_shape([None])\n",
    "  label.set_shape([])\n",
    "\n",
    "  return encoded_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "Gn5PgB2UolOg",
    "outputId": "e211010d-1bb0-4562-f54e-5cc940175277"
   },
   "outputs": [],
   "source": [
    "example_text = next(iter(train_dataset))[0].numpy()\n",
    "example_text = next(iter(train_dataset))[0].numpy()\n",
    "print(example_text)\n",
    "encoded_example = encoder.encode(example_text)\n",
    "print(encoded_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "5QJuPtEL7loC",
    "outputId": "6e404f47-2ca9-45e7-c9b6-f70f1ceca3b7"
   },
   "outputs": [],
   "source": [
    "# Encode sentences\n",
    "all_encoded_data = train_dataset.map(encode_map_fn)\n",
    "for ex in all_encoded_data.take(5):\n",
    "  print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_-4yjieB-7F"
   },
   "outputs": [],
   "source": [
    "# Shuffle into train/test data and add \n",
    "BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 64\n",
    "TAKE_SIZE = 2000\n",
    "\n",
    "train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\n",
    "train_data = train_data.padded_batch(BATCH_SIZE)\n",
    "\n",
    "test_data = all_encoded_data.take(TAKE_SIZE)\n",
    "test_data = test_data.padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "Kfe1yIAUCxnA",
    "outputId": "e9560bf0-f880-41ab-8d87-64de18ff2d11"
   },
   "outputs": [],
   "source": [
    "sample_text, sample_labels = next(iter(train_data))\n",
    "\n",
    "sample_text[0], encoder.decode(sample_text[0].numpy()), sample_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jIPas-ktM7Q"
   },
   "source": [
    "# Tensorflow Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "zZNCRVQjC7zX",
    "outputId": "b26b2b04-93ec-43f0-8f7a-c536cb1f6231"
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, 64))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
    "\n",
    "# One or more dense layers.\n",
    "# Edit the list in the `for` line to experiment with layer sizes.\n",
    "for units in [64, 64]:\n",
    "  model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "\n",
    "# Output layer. The first argument is the number of labels.\n",
    "model.add(tf.keras.layers.Dense(5))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "YLyHFC9uElSp",
    "outputId": "4fcdf5dd-13a4-46ca-d108-b3f736d35d3e"
   },
   "outputs": [],
   "source": [
    "model.fit(train_data, epochs=3, validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEht5nKQE1N1"
   },
   "outputs": [],
   "source": [
    "eval_loss, eval_acc = model.evaluate(test_data)\n",
    "\n",
    "print('\\nEval loss: {:.3f}, Eval accuracy: {:.3f}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBS-AG2BtVwV"
   },
   "source": [
    "# Tensorflow Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "tEJ5-CL0tYQw",
    "outputId": "2da6b012-c592-4ae9-878f-7842dbb71618"
   },
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(1000, 5)\n",
    "result = embedding_layer(tf.constant([1,2,3]))\n",
    "result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "Fy8fAq1Runpu",
    "outputId": "acf37ef9-c0b2-4982-bf19-537473e20440"
   },
   "outputs": [],
   "source": [
    "embedding_dim=16\n",
    "\n",
    "model = keras.Sequential([\n",
    "  layers.Embedding(vocab_size, embedding_dim),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  # layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(5)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "N4JZBdrauwia",
    "outputId": "6411e144-6fba-4a11-c12b-f4aa239f75b0"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=3,\n",
    "    validation_data=test_data, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "SI1vWUD4zOm7",
    "outputId": "0814cf37-3200-456a-b223-bebcda916de9"
   },
   "outputs": [],
   "source": [
    "# Retrive the learned embeddings\n",
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)\n",
    "\n",
    "# Save to disk\n",
    "import io\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for num, word in enumerate(encoder.tokens):\n",
    "  vec = weights[num+1] # skip 0, it's padding.\n",
    "  out_m.write(word + \"\\n\")\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()\n",
    "\n",
    "# Download to PC\n",
    "try:\n",
    "  from google.colab import files\n",
    "except ImportError:\n",
    "   pass\n",
    "else:\n",
    "  files.download('vecs.tsv')\n",
    "  files.download('meta.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF4bB9HVCGGR"
   },
   "source": [
    "# SciBERT Model For Sentence Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "tEWpbCTNCJbp",
    "outputId": "49109daa-5430-4f7d-f07e-ee3b5bfdb486"
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "QyIfIV1jCV9B",
    "outputId": "43b93ee8-ff1e-4f30-da57-cb1a894721cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scibert_tokenizer is type: <class 'transformers.tokenization_bert.BertTokenizer'>\n",
      "    scibert_model is type: <class 'transformers.modeling_bert.BertModel'>\n"
     ]
    }
   ],
   "source": [
    "scibert_model = BertModel.from_pretrained(\"allenai/scibert_scivocab_uncased\",\n",
    "                                  output_hidden_states=True)\n",
    "scibert_tokenizer = BertTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "\n",
    "print('scibert_tokenizer is type:', type(scibert_tokenizer))\n",
    "print('    scibert_model is type:', type(scibert_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Xk6zdIL6CapG"
   },
   "outputs": [],
   "source": [
    "def get_word_indeces(tokenizer, text, word):\n",
    "    '''\n",
    "    Determines the index or indeces of the tokens corresponding to `word`\n",
    "    within `text`. `word` can consist of multiple words, e.g., \"cell biology\".\n",
    "    \n",
    "    Determining the indeces is tricky because words can be broken into multiple\n",
    "    tokens. I've solved this with a rather roundabout approach--I replace `word`\n",
    "    with the correct number of `[MASK]` tokens, and then find these in the \n",
    "    tokenized result. \n",
    "    '''\n",
    "    # Tokenize the 'word'--it may be broken into multiple tokens or subwords.\n",
    "    word_tokens = tokenizer.tokenize(word)\n",
    "\n",
    "    # Create a sequence of `[MASK]` tokens to put in place of `word`.\n",
    "    masks_str = ' '.join(['[MASK]']*len(word_tokens))\n",
    "\n",
    "    # Replace the word with mask tokens.\n",
    "    text_masked = text.replace(word, masks_str)\n",
    "\n",
    "    # `encode` performs multiple functions:\n",
    "    #   1. Tokenizes the text\n",
    "    #   2. Maps the tokens to their IDs\n",
    "    #   3. Adds the special [CLS] and [SEP] tokens.\n",
    "    input_ids = tokenizer.encode(text_masked)\n",
    "\n",
    "    # Use numpy's `where` function to find all indeces of the [MASK] token.\n",
    "    mask_token_indeces = np.where(np.array(input_ids) == tokenizer.mask_token_id)[0]\n",
    "\n",
    "    return mask_token_indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ug_GZMKjFnIK"
   },
   "outputs": [],
   "source": [
    "def get_embedding(b_model, b_tokenizer, text):\n",
    "    '''\n",
    "    Uses the provided model and tokenizer to produce an embedding for the\n",
    "    provided `text`\n",
    "    '''\n",
    "\n",
    "    # Encode the text, adding the (required!) special tokens, and converting to\n",
    "    # PyTorch tensors.\n",
    "    encoded_dict = b_tokenizer.encode_plus(\n",
    "                        text,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                )\n",
    "\n",
    "    input_ids = encoded_dict['input_ids']\n",
    "    \n",
    "    b_model.eval()\n",
    "\n",
    "    # Run the text through the model and get the hidden states.\n",
    "    bert_outputs = b_model(input_ids)\n",
    "    \n",
    "    # Run the text through BERT, and collect all of the hidden states produced\n",
    "    # from all 12 layers. \n",
    "    with torch.no_grad():\n",
    "\n",
    "        outputs = b_model(input_ids)\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    # `hidden_states` has shape [13 x 1 x <sentence length> x 768]\n",
    "\n",
    "    # Select the embeddings from the second to last layer.\n",
    "    # `token_vecs` is a tensor with shape [<sent length> x 768]\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "\n",
    "    # Calculate the average of all token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "\n",
    "    # Convert to numpy array.\n",
    "    sentence_embedding = sentence_embedding.detach().numpy()\n",
    "\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "ujuY_wU_Fp_R",
    "outputId": "1613754a-e5de-40f1-b3e8-a26e5d7ae37c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding sizes:\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "text = \"hydrogels are hydrophilic polymer networks which may absorb from 10â€“20% (an arbitrary lower limit) up to thousands of times their dry weight in water.\"\n",
    "\n",
    "# Get the embedding for the sentence, as well as an embedding for 'hydrogels'.\n",
    "sen_emb = get_embedding(scibert_model, scibert_tokenizer, text)\n",
    "\n",
    "print('Embedding sizes:')\n",
    "print(sen_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tyLDA81MCk2"
   },
   "source": [
    "Look into using TF cause this is slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "4WL7iwzGKVHX",
    "outputId": "a9c2aadb-f3c8-4343-ee30-fbf9a19d0549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88797 88797\n",
      "139.64\n",
      "88797\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import timeit\n",
    "\n",
    "embeddings = []\n",
    "length = len(df['sentence'].tolist())\n",
    "index = 0\n",
    "\n",
    "start = timeit.default_timer()\n",
    "for sentence in df['sentence'].tolist():\n",
    "    clear_output(wait=True)\n",
    "    index += 1\n",
    "    sen_emb = get_embedding(scibert_model, scibert_tokenizer, sentence)\n",
    "    embeddings.append(sen_emb)\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    if (index/length*100) < 1:\n",
    "        expected_time = \"Calculating...\"\n",
    "\n",
    "    else:\n",
    "        time_perc = timeit.default_timer()\n",
    "        expected_time = np.round( (time_perc-start) /(index/length) /60,2)\n",
    "\n",
    "    print(index, length)\n",
    "    print(expected_time)\n",
    "\n",
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PmZkrrRX_CGP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>To investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Secondary outcome measures included the Wester...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>There was a clinically relevant reduction in t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Further , there was a clinically relevant redu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           sentence  code\n",
       "0  OBJECTIVE  To investigate the efficacy of @ weeks of dail...     3\n",
       "1    METHODS  Outcome measures included pain reduction and i...     2\n",
       "2    METHODS  Secondary outcome measures included the Wester...     2\n",
       "3    RESULTS  There was a clinically relevant reduction in t...     4\n",
       "4    RESULTS  Further , there was a clinically relevant redu...     4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LXAjeF4U-ydM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>code</th>\n",
       "      <th>scibert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>To investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.44510403, -0.31423956, -0.45745727, 0.4200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.4775299, -0.46893463, -0.22414015, 0.22520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Secondary outcome measures included the Wester...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.61925375, -0.19193889, -0.38404435, 0.2082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>There was a clinically relevant reduction in t...</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.5922383, -0.41908544, -0.33248687, 0.55146...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Further , there was a clinically relevant redu...</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.38201377, -0.53494513, 0.1772025, 0.381558...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           sentence  code  \\\n",
       "0  OBJECTIVE  To investigate the efficacy of @ weeks of dail...     3   \n",
       "1    METHODS  Outcome measures included pain reduction and i...     2   \n",
       "2    METHODS  Secondary outcome measures included the Wester...     2   \n",
       "3    RESULTS  There was a clinically relevant reduction in t...     4   \n",
       "4    RESULTS  Further , there was a clinically relevant redu...     4   \n",
       "\n",
       "                                             scibert  \n",
       "0  [-0.44510403, -0.31423956, -0.45745727, 0.4200...  \n",
       "1  [-0.4775299, -0.46893463, -0.22414015, 0.22520...  \n",
       "2  [-0.61925375, -0.19193889, -0.38404435, 0.2082...  \n",
       "3  [-0.5922383, -0.41908544, -0.33248687, 0.55146...  \n",
       "4  [-0.38201377, -0.53494513, 0.1772025, 0.381558...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['scibert'] = embeddings\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Y7kcDqCn_GnI"
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"./df_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating SciBert Embedded Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>code</th>\n",
       "      <th>scibert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>To investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.44510403, -0.31423956, -0.45745727, 0.4200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.4775299, -0.46893463, -0.22414015, 0.22520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Secondary outcome measures included the Wester...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.61925375, -0.19193889, -0.38404435, 0.2082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>There was a clinically relevant reduction in t...</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.5922383, -0.41908544, -0.33248687, 0.55146...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Further , there was a clinically relevant redu...</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.38201377, -0.53494513, 0.1772025, 0.381558...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>The Outcome Measures in Rheumatology Clinical ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.027787112, 0.23189485, -0.3841277, 0.625988...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>Emotional eating is associated with overeating...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.6055013, -0.14416914, -0.32580143, 0.12642...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>The aim of this study was to test if attention...</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.37356007, 0.10462127, -0.011478976, -0.169...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Participants ( N = @ ) were randomly assigned ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.23434164, 0.32432234, -0.29593608, -0.39225...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Self-reported emotional eating was assessed wi...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.65840876, 0.21802892, -0.24623804, -0.1824...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Yet , attention maintenance on food cues was s...</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.19438043, -0.038107645, 0.15598723, 0.2300...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>Results further suggest that attention mainten...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.06832442, 0.22197606, -0.21255746, 0.14556...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>We tested whether theory-based education incre...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.24022587, 0.019652834, 0.121256776, -0.116...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Intervention arms : ( @ ) Full Education combi...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.35353863, -0.023675352, 0.11459824, 0.24104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Follow-up visits checked alarm operability in ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.5296404, 0.16995905, 0.2568119, 0.46228915...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Regressions controlled for alarm status preint...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.44354755, 0.061076682, -0.6860289, -0.1354...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Working alarms per home rose @ % .</td>\n",
       "      <td>4</td>\n",
       "      <td>[-1.0388806, 0.52558917, 0.045176875, 0.036362...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>Without exceeding typical fire department inst...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.19592582, -0.1943504, 0.17269269, 0.010289...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>Two years after installation , for every three...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.012061362, 0.26443887, -0.028506553, -0.048...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>To evaluate the performance ( efficacy , safet...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.047299154, -0.27056786, 0.21400625, 0.49091...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                           sentence  code  \\\n",
       "0     OBJECTIVE  To investigate the efficacy of @ weeks of dail...     3   \n",
       "1       METHODS  Outcome measures included pain reduction and i...     2   \n",
       "2       METHODS  Secondary outcome measures included the Wester...     2   \n",
       "3       RESULTS  There was a clinically relevant reduction in t...     4   \n",
       "4       RESULTS  Further , there was a clinically relevant redu...     4   \n",
       "5       RESULTS  The Outcome Measures in Rheumatology Clinical ...     4   \n",
       "7    BACKGROUND  Emotional eating is associated with overeating...     0   \n",
       "8     OBJECTIVE  The aim of this study was to test if attention...     3   \n",
       "9       METHODS  Participants ( N = @ ) were randomly assigned ...     2   \n",
       "10      METHODS  Self-reported emotional eating was assessed wi...     2   \n",
       "11      RESULTS  Yet , attention maintenance on food cues was s...     4   \n",
       "12  CONCLUSIONS  Results further suggest that attention mainten...     1   \n",
       "14   BACKGROUND  We tested whether theory-based education incre...     0   \n",
       "15      METHODS  Intervention arms : ( @ ) Full Education combi...     2   \n",
       "16      METHODS  Follow-up visits checked alarm operability in ...     2   \n",
       "17      METHODS  Regressions controlled for alarm status preint...     2   \n",
       "18      RESULTS                 Working alarms per home rose @ % .     4   \n",
       "19  CONCLUSIONS  Without exceeding typical fire department inst...     1   \n",
       "20  CONCLUSIONS  Two years after installation , for every three...     1   \n",
       "22    OBJECTIVE  To evaluate the performance ( efficacy , safet...     3   \n",
       "\n",
       "                                              scibert  \n",
       "0   [-0.44510403, -0.31423956, -0.45745727, 0.4200...  \n",
       "1   [-0.4775299, -0.46893463, -0.22414015, 0.22520...  \n",
       "2   [-0.61925375, -0.19193889, -0.38404435, 0.2082...  \n",
       "3   [-0.5922383, -0.41908544, -0.33248687, 0.55146...  \n",
       "4   [-0.38201377, -0.53494513, 0.1772025, 0.381558...  \n",
       "5   [0.027787112, 0.23189485, -0.3841277, 0.625988...  \n",
       "7   [-0.6055013, -0.14416914, -0.32580143, 0.12642...  \n",
       "8   [-0.37356007, 0.10462127, -0.011478976, -0.169...  \n",
       "9   [0.23434164, 0.32432234, -0.29593608, -0.39225...  \n",
       "10  [-0.65840876, 0.21802892, -0.24623804, -0.1824...  \n",
       "11  [-0.19438043, -0.038107645, 0.15598723, 0.2300...  \n",
       "12  [-0.06832442, 0.22197606, -0.21255746, 0.14556...  \n",
       "14  [-0.24022587, 0.019652834, 0.121256776, -0.116...  \n",
       "15  [0.35353863, -0.023675352, 0.11459824, 0.24104...  \n",
       "16  [-0.5296404, 0.16995905, 0.2568119, 0.46228915...  \n",
       "17  [-0.44354755, 0.061076682, -0.6860289, -0.1354...  \n",
       "18  [-1.0388806, 0.52558917, 0.045176875, 0.036362...  \n",
       "19  [-0.19592582, -0.1943504, 0.17269269, 0.010289...  \n",
       "20  [0.012061362, 0.26443887, -0.028506553, -0.048...  \n",
       "22  [0.047299154, -0.27056786, 0.21400625, 0.49091...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "df = pd.read_pickle(\"./df_embeddings.pkl\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0 -0.445104 -0.314240 -0.457457  0.420030  0.173084 -0.065855  0.061035   \n",
      "1 -0.477530 -0.468935 -0.224140  0.225207 -0.628368 -0.186920  0.422231   \n",
      "2 -0.619254 -0.191939 -0.384044  0.208252 -0.608025  0.478259  0.203383   \n",
      "3 -0.592238 -0.419085 -0.332487  0.551465 -0.382408 -0.024462  0.144854   \n",
      "4 -0.382014 -0.534945  0.177202  0.381558 -0.054668  0.454776 -0.134878   \n",
      "\n",
      "          7         8         9  ...       759       760       761       762  \\\n",
      "0  0.711958  0.052800 -0.041667  ...  0.480911 -0.697301 -0.227034  0.044675   \n",
      "1  1.097500 -0.643063  0.386619  ...  0.211434 -0.202346 -0.248359  0.104181   \n",
      "2  0.504245 -0.398351  0.235902  ... -0.013601 -0.074485 -0.533143 -0.200412   \n",
      "3  0.251451 -0.027627 -0.236988  ...  0.349020 -0.284310 -0.204176  0.287185   \n",
      "4  0.459382  0.098035 -0.291524  ...  0.331686 -0.720776 -0.054727  0.102350   \n",
      "\n",
      "        763       764       765       766       767      label  \n",
      "0 -0.162566 -0.093259 -0.209625 -0.359225 -0.685882  OBJECTIVE  \n",
      "1 -0.559502 -0.062833 -0.059075  0.132159 -0.735158    METHODS  \n",
      "2 -0.421800 -0.239700  0.209524  0.155945 -0.263110    METHODS  \n",
      "3 -0.188009 -0.387381 -0.018977  0.174906 -0.650318    RESULTS  \n",
      "4  0.043568 -0.225486 -0.045171 -0.377394 -0.312927    RESULTS  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "             0         1         2         3         4         5         6  \\\n",
      "2922 -0.179181 -0.023371 -0.210686 -0.242063 -0.512513  0.281127  0.858888   \n",
      "2923 -0.149055  0.264892 -0.202001  1.163043 -0.288614 -0.327484  0.558682   \n",
      "2924  0.198227 -0.137781 -0.229628  0.585217 -0.071734 -0.702560  0.510642   \n",
      "2925 -0.269619 -0.648137 -0.083688  0.094512 -0.046200 -0.612689  0.431117   \n",
      "2926  0.522997 -0.185134 -0.627226  0.465693  0.143564  0.530790  0.550384   \n",
      "\n",
      "             7         8         9  ...       759       760       761  \\\n",
      "2922 -0.073471 -0.509127 -0.322709  ...  0.511621 -0.875685 -0.297404   \n",
      "2923  0.335087  0.216169 -0.263239  ...  0.434298 -0.527897 -0.071797   \n",
      "2924  0.637680 -0.089519 -0.114321  ...  0.298609 -0.420229  0.061906   \n",
      "2925  0.465337 -0.174616 -0.501447  ...  0.211606 -0.500682  0.330816   \n",
      "2926  0.435149 -0.144463 -0.659012  ... -0.213851 -0.376249 -0.339848   \n",
      "\n",
      "           762       763       764       765       766       767        label  \n",
      "2922 -0.154243 -0.176224 -0.704339 -0.151247 -0.221556 -0.216853      RESULTS  \n",
      "2923 -0.477455 -0.146878 -0.745445  0.142700 -0.653456 -0.114468      RESULTS  \n",
      "2924 -0.388552 -0.196148 -0.375823 -0.040152 -0.271852 -0.069972      RESULTS  \n",
      "2925 -0.179172 -0.114065  0.274652  0.087079 -0.179099 -0.031582  CONCLUSIONS  \n",
      "2926  0.213141 -0.506947 -0.391220  0.120304  0.819156 -0.080276  CONCLUSIONS  \n",
      "\n",
      "[5 rows x 769 columns]\n"
     ]
    }
   ],
   "source": [
    "# Export to weka\n",
    "export_df = pd.DataFrame(df['scibert'][:2500].tolist(), index=df.index[:2500])\n",
    "export_df['label'] = df['label'][:2500]\n",
    "\n",
    "print(export_df.head())\n",
    "\n",
    "export_df.to_csv('./weka.csv', index=False)\n",
    "\n",
    "export_df = pd.DataFrame(df['scibert'][2500:3500].tolist(), index=df.index[2500:3500])\n",
    "export_df['label'] = df['label'][2500:3500]\n",
    "print(export_df.head())\n",
    "export_df.to_csv('./weka_test.csv', index=False)\n",
    "\n",
    "# import arff\n",
    "# arff.dump('filename.arff'\n",
    "#       , export_df.values\n",
    "#       , relation='relation name'\n",
    "#       , names=export_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>code</th>\n",
       "      <th>scibert</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BACKGROUND</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONCLUSIONS</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>METHODS</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBJECTIVE</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESULTS</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentence  code  scibert\n",
       "label                               \n",
       "BACKGROUND        500   500      500\n",
       "CONCLUSIONS       500   500      500\n",
       "METHODS           500   500      500\n",
       "OBJECTIVE         500   500      500\n",
       "RESULTS           500   500      500"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample even number from each class\n",
    "even_df = df.groupby('code').apply(lambda x: x.sample(n=500)).reset_index(drop = True)\n",
    "even_test = df.groupby('code').apply(lambda x: x.sample(n=200)).reset_index(drop = True)\n",
    "even_df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.6848414470728751\n",
      "MCC\n",
      "0.7032191336917659\n",
      "Accuracy\n",
      "0.78\n",
      "[[ 72  23  10  19   3]\n",
      " [ 21 106   7   2  23]\n",
      " [ 15   3 294   6  22]\n",
      " [ 26   7   8  25   0]\n",
      " [  2   6  17   0 283]]\n"
     ]
    }
   ],
   "source": [
    "# KNN with standard data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(metric=\"manhattan\", n_jobs=-1)\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(confusion_matrix(df['code'][2500:3500].tolist(), pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6917715226751202\n",
      "0.6138397806336067\n",
      "0.691\n",
      "[[112  21   5  60   2]\n",
      " [ 25 138   4   8  25]\n",
      " [ 12   4 165  11   8]\n",
      " [ 61  11  13 114   1]\n",
      " [  3  21  13   1 162]]\n"
     ]
    }
   ],
   "source": [
    "# KNN with balanced data\n",
    "train_data = even_df['scibert'].tolist()\n",
    "train_labels = even_df['code'].tolist()\n",
    "test_data = even_test['scibert'].tolist()\n",
    "test_labels = even_test['code'].tolist()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_even = KNeighborsClassifier(metric=\"manhattan\", n_jobs=-1)\n",
    "model_even.fit(train_data, train_labels)\n",
    "pred_even = model_even.predict(test_data)\n",
    "\n",
    "print(f1_score(test_labels, pred_even, average=\"macro\"))\n",
    "print(matthews_corrcoef(test_labels, pred_even))\n",
    "print(accuracy_score(test_labels, pred_even))\n",
    "print(confusion_matrix(test_labels, pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.6681035538397584\n",
      "0.6709305896250097\n",
      "MCC\n",
      "0.6634952331940656\n",
      "0.6558606143364742\n",
      "Accuracy\n",
      "0.747\n",
      "0.741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB()\n",
    "model_even = BernoulliNB()\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.6969765214942665\n",
      "0.680103550567688\n",
      "MCC\n",
      "0.6918251118653097\n",
      "0.6686883947774092\n",
      "Accuracy\n",
      "0.767\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model_even = GaussianNB()\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.46094697692739006\n",
      "0.4676075892099999\n",
      "MCC\n",
      "0.4103338396416756\n",
      "0.38655254976388786\n",
      "Accuracy\n",
      "0.559\n",
      "0.525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model_even = DecisionTreeClassifier()\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/connor/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.6931498071426793\n",
      "0.6671190236890402\n",
      "MCC\n",
      "0.7125171448205804\n",
      "0.6789894636994003\n",
      "Accuracy\n",
      "0.787\n",
      "0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/connor/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC(multi_class=\"ovr\", max_iter=1000)\n",
    "model_even = LinearSVC(multi_class=\"ovr\", max_iter=1000)\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.742674548713269\n",
      "MCC\n",
      "0.7866132899786072\n",
      "Accuracy\n",
      "0.842\n",
      "[[ 89   8  12  16   2]\n",
      " [ 20 117   5   0  17]\n",
      " [  4   2 324   2   8]\n",
      " [ 31   5   7  22   1]\n",
      " [  0   5  13   0 290]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='rbf', gamma=0.02, C=2)\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(confusion_matrix(df['code'][2500:3500].tolist(), pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7675276421811181\n",
      "0.7119328931803347\n",
      "0.769\n",
      "[[127  11   9  52   1]\n",
      " [ 13 163   4   2  18]\n",
      " [  8   1 186   2   3]\n",
      " [ 55   4  15 126   0]\n",
      " [  1  14  18   0 167]]\n"
     ]
    }
   ],
   "source": [
    "# Even data\n",
    "from sklearn.svm import SVC\n",
    "model_even = SVC(kernel='rbf', gamma=0.02, C=2)\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "pred_even = model_even.predict(even_test['scibert'].tolist())\n",
    "print(f1_score(even_test['code'].tolist(), pred_even, average=\"macro\"))\n",
    "print(matthews_corrcoef(even_test['code'].tolist(), pred_even))\n",
    "print(accuracy_score(even_test['code'].tolist(), pred_even))\n",
    "print(confusion_matrix(even_test['code'].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0 -0.445104 -0.314240 -0.457457  0.420030  0.173084 -0.065855  0.061035   \n",
      "1 -0.477530 -0.468935 -0.224140  0.225207 -0.628368 -0.186920  0.422231   \n",
      "2 -0.619254 -0.191939 -0.384044  0.208252 -0.608025  0.478259  0.203383   \n",
      "3 -0.592238 -0.419085 -0.332487  0.551465 -0.382408 -0.024462  0.144854   \n",
      "4 -0.382014 -0.534945  0.177202  0.381558 -0.054668  0.454776 -0.134878   \n",
      "\n",
      "          7         8         9  ...       759       760       761       762  \\\n",
      "0  0.711958  0.052800 -0.041667  ...  0.480911 -0.697301 -0.227034  0.044675   \n",
      "1  1.097500 -0.643063  0.386619  ...  0.211434 -0.202346 -0.248359  0.104181   \n",
      "2  0.504245 -0.398351  0.235902  ... -0.013601 -0.074485 -0.533143 -0.200412   \n",
      "3  0.251451 -0.027627 -0.236988  ...  0.349020 -0.284310 -0.204176  0.287185   \n",
      "4  0.459382  0.098035 -0.291524  ...  0.331686 -0.720776 -0.054727  0.102350   \n",
      "\n",
      "        763       764       765       766       767  intercept  \n",
      "0 -0.162566 -0.093259 -0.209625 -0.359225 -0.685882          1  \n",
      "1 -0.559502 -0.062833 -0.059075  0.132159 -0.735158          1  \n",
      "2 -0.421800 -0.239700  0.209524  0.155945 -0.263110          1  \n",
      "3 -0.188009 -0.387381 -0.018977  0.174906 -0.650318          1  \n",
      "4  0.043568 -0.225486 -0.045171 -0.377394 -0.312927          1  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "   code\n",
      "0  -1.0\n",
      "1  -1.0\n",
      "2  -1.0\n",
      "3  -1.0\n",
      "4  -1.0\n",
      "splitting dataset into train and test sets...\n",
      "training started...\n",
      "2000\n",
      "Epoch is: 1 and Cost is: 936469832.3277969\n",
      "2000\n",
      "Epoch is: 2 and Cost is: 1854595081.687304\n",
      "2000\n",
      "Epoch is: 4 and Cost is: 3685317412.1332917\n",
      "2000\n",
      "Epoch is: 8 and Cost is: 7324984423.134109\n",
      "2000\n",
      "Epoch is: 16 and Cost is: 14518023040.492966\n",
      "2000\n",
      "Epoch is: 32 and Cost is: 28564782140.038044\n",
      "2000\n",
      "Epoch is: 64 and Cost is: 55350362391.31657\n",
      "2000\n",
      "Epoch is: 128 and Cost is: 104059876842.33856\n",
      "2000\n",
      "Epoch is: 256 and Cost is: 184674325083.92294\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2e20a614850a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0mregularization_strength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.000001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-2e20a614850a>\u001b[0m in \u001b[0;36minit\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training started...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training finished.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weights are: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-2e20a614850a>\u001b[0m in \u001b[0;36msgd\u001b[0;34m(features, outputs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# shuffle to prevent repeating update cycles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mascent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_cost_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \"\"\"\n\u001b[1;32m    700\u001b[0m     \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;31m# convert sparse matrices to CSR for row-based indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m     \u001b[0mresampled_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresampled_arrays\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;31m# syntactic sugar for the unit argument case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;31m# convert sparse matrices to CSR for row-based indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m     \u001b[0mresampled_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresampled_arrays\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;31m# syntactic sugar for the unit argument case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pandas_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_array_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_array_indexing\u001b[0;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# >> FEATURE SELECTION << #\n",
    "def remove_correlated_features(X):\n",
    "    corr_threshold = 0.9\n",
    "    corr = X.corr()\n",
    "    drop_columns = np.full(corr.shape[0], False, dtype=bool)\n",
    "    for i in range(corr.shape[0]):\n",
    "        for j in range(i + 1, corr.shape[0]):\n",
    "            if corr.iloc[i, j] >= corr_threshold:\n",
    "                drop_columns[j] = True\n",
    "    columns_dropped = X.columns[drop_columns]\n",
    "    X.drop(columns_dropped, axis=1, inplace=True)\n",
    "    return columns_dropped\n",
    "\n",
    "\n",
    "def remove_less_significant_features(X, Y):\n",
    "    sl = 0.05\n",
    "    regression_ols = None\n",
    "    columns_dropped = np.array([])\n",
    "    for itr in range(0, len(X.columns)):\n",
    "        regression_ols = sm.OLS(Y, X).fit()\n",
    "        max_col = regression_ols.pvalues.idxmax()\n",
    "        max_val = regression_ols.pvalues.max()\n",
    "        if max_val > sl:\n",
    "            X.drop(max_col, axis='columns', inplace=True)\n",
    "            columns_dropped = np.append(columns_dropped, [max_col])\n",
    "        else:\n",
    "            break\n",
    "    regression_ols.summary()\n",
    "    return columns_dropped\n",
    "\n",
    "\n",
    "##############################\n",
    "\n",
    "\n",
    "# >> MODEL TRAINING << #\n",
    "def compute_cost(W, X, Y):\n",
    "    # calculate hinge loss\n",
    "    N = X.shape[0]\n",
    "    print(N)\n",
    "    distances = 1 - Y * (np.dot(X, W))\n",
    "    distances[distances < 0] = 0  # equivalent to max(0, distance)\n",
    "    hinge_loss = regularization_strength * (np.sum(distances) / N)\n",
    "\n",
    "    # calculate cost\n",
    "    cost = 1 / 2 * np.dot(W, W) + hinge_loss\n",
    "    return cost\n",
    "\n",
    "\n",
    "# I haven't tested it but this same function should work for\n",
    "# vanilla and mini-batch gradient descent as well\n",
    "def calculate_cost_gradient(W, X_batch, Y_batch):\n",
    "    # if only one example is passed (eg. in case of SGD)\n",
    "    if type(Y_batch) == np.float64:\n",
    "        Y_batch = np.array([Y_batch])\n",
    "        X_batch = np.array([X_batch])  # gives multidimensional array\n",
    "\n",
    "    distance = 1 - (Y_batch * np.dot(X_batch, W))\n",
    "    dw = np.zeros(len(W))\n",
    "\n",
    "    for ind, d in enumerate(distance):\n",
    "        if max(0, d) == 0:\n",
    "            di = W\n",
    "        else:\n",
    "            di = W - (regularization_strength * Y_batch[ind] * X_batch[ind])\n",
    "        dw += di\n",
    "\n",
    "    dw = dw/len(Y_batch)  # average\n",
    "    return dw\n",
    "\n",
    "\n",
    "def sgd(features, outputs):\n",
    "    max_epochs = 5000\n",
    "    weights = np.zeros(features.shape[1])\n",
    "    nth = 0\n",
    "    prev_cost = float(\"inf\")\n",
    "    cost_threshold = 0.01  # in percent\n",
    "    # stochastic gradient descent\n",
    "    for epoch in range(1, max_epochs):\n",
    "        # shuffle to prevent repeating update cycles\n",
    "        X, Y = shuffle(features, outputs)\n",
    "        for ind, x in enumerate(X):\n",
    "            ascent = calculate_cost_gradient(weights, x, Y[ind])\n",
    "            weights = weights - (learning_rate * ascent)\n",
    "\n",
    "        # convergence check on 2^nth epoch\n",
    "        if epoch == 2 ** nth or epoch == max_epochs - 1:\n",
    "            cost = compute_cost(weights, features, outputs)\n",
    "            print(\"Epoch is: {} and Cost is: {}\".format(epoch, cost))\n",
    "            # stoppage criterion\n",
    "            if abs(prev_cost - cost) < cost_threshold * prev_cost:\n",
    "                return weights\n",
    "            prev_cost = cost\n",
    "            nth += 1\n",
    "    return weights\n",
    "\n",
    "\n",
    "########################\n",
    "\n",
    "\n",
    "def init():\n",
    "    diag_map = {0: 1.0, 1: -1.0, 2: -1.0, 3: -1.0, 4: -1.0}\n",
    "\n",
    "    # put features & outputs in different data frames\n",
    "    Y = pd.DataFrame(df['code'][:2500].map(diag_map))\n",
    "    X = pd.DataFrame(df['scibert'][:2500].tolist(), index= df.index[:2500])\n",
    "\n",
    "    # filter features\n",
    "#     remove_correlated_features(X)\n",
    "#     remove_less_significant_features(X, Y)\n",
    "\n",
    "    # normalize data for better convergence and to prevent overflow\n",
    "#     X_normalized = MinMaxScaler().fit_transform(X.values)\n",
    "#     X = pd.DataFrame(X_normalized)\n",
    "\n",
    "    # insert 1 in every row for intercept b\n",
    "    X.insert(loc=len(X.columns), column='intercept', value=1)\n",
    "\n",
    "    print(X.head())\n",
    "    print(Y.head())\n",
    "    \n",
    "    # split data into train and test set\n",
    "    print(\"splitting dataset into train and test sets...\")\n",
    "    X_train, X_test, y_train, y_test = tts(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # train the model\n",
    "    print(\"training started...\")\n",
    "    W = sgd(X_train.to_numpy(), y_train.to_numpy())\n",
    "    print(\"training finished.\")\n",
    "    print(\"weights are: {}\".format(W))\n",
    "\n",
    "    # testing the model\n",
    "    print(\"testing the model...\")\n",
    "    y_train_predicted = np.array([])\n",
    "    for i in range(X_train.shape[0]):\n",
    "        yp = np.sign(np.dot(X_train.to_numpy()[i], W))\n",
    "        y_train_predicted = np.append(y_train_predicted, yp)\n",
    "\n",
    "    y_test_predicted = np.array([])\n",
    "    for i in range(X_test.shape[0]):\n",
    "        yp = np.sign(np.dot(X_test.to_numpy()[i], W))\n",
    "        y_test_predicted = np.append(y_test_predicted, yp)\n",
    "\n",
    "    print(\"accuracy on test dataset: {}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "    print(\"recall on test dataset: {}\".format(recall_score(y_test, y_test_predicted)))\n",
    "    print(\"precision on test dataset: {}\".format(recall_score(y_test, y_test_predicted)))\n",
    "\n",
    "\n",
    "# set hyper-parameters and call init\n",
    "regularization_strength = 10000\n",
    "learning_rate = 0.000001\n",
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.7231861816607512\n",
      "0.7153398986547954\n",
      "MCC\n",
      "0.7527761095624504\n",
      "0.7345170631965806\n",
      "Accuracy\n",
      "0.817\n",
      "0.802\n",
      "[[ 71  16   3  32   5]\n",
      " [ 16 113   3  10  17]\n",
      " [ 13   0 309   5  13]\n",
      " [ 19   6   5  35   1]\n",
      " [  1  14  18   1 274]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(multi_class=\"ovr\", max_iter=1000)\n",
    "model_even = LogisticRegression(multi_class=\"ovr\", max_iter=1000)\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(confusion_matrix(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.7058321377086436\n",
      "0.7256700391541749\n",
      "MCC\n",
      "0.7370274149726393\n",
      "0.7448034226562301\n",
      "Accuracy\n",
      "0.805\n",
      "0.809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier()\n",
    "model_even = MLPClassifier()\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.6976264130136529\n",
      "0.7122919005635008\n",
      "MCC\n",
      "0.7286235564447606\n",
      "0.7298053612649003\n",
      "Accuracy\n",
      "0.798\n",
      "0.799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "model = Perceptron()\n",
    "model_even = Perceptron()\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 0.7245 - accuracy: 0.7280 - val_loss: 0.5772 - val_accuracy: 0.8020\n",
      "Epoch 2/4\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.4701 - accuracy: 0.8300 - val_loss: 0.5675 - val_accuracy: 0.8090\n",
      "Epoch 3/4\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.3893 - accuracy: 0.8580 - val_loss: 0.6605 - val_accuracy: 0.7610\n",
      "Epoch 4/4\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 0.3543 - accuracy: 0.8656 - val_loss: 0.5173 - val_accuracy: 0.8220\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.8220\n",
      "\n",
      "Eval loss: 0.517, Eval accuracy: 0.822\n",
      "F1 Score\n",
      "0.7312273609053561\n",
      "MCC\n",
      "0.7599122337675305\n",
      "Accuracy\n",
      "0.822\n",
      "Confusion Matrix\n",
      "[[ 86  12   9  16   4]\n",
      " [ 21 111   5   3  19]\n",
      " [ 10   1 319   3   7]\n",
      " [ 29   5   5  26   1]\n",
      " [  0   7  21   0 280]]\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow NN\n",
    "import numpy as np\n",
    "\n",
    "# Build model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(768, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Output layer. The first argument is the number of labels.\n",
    "model.add(tf.keras.layers.Dense(5))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "train_em = df['scibert'][:2500]\n",
    "train_em = np.array(train_em.tolist())\n",
    "train_label = df['code'][:2500]\n",
    "train_label = np.array(train_label.tolist())\n",
    "\n",
    "test_em = df['scibert'][2500:3500]\n",
    "test_em = np.array(test_em.tolist())\n",
    "test_label = df['code'][2500:3500]\n",
    "test_label = np.array(test_label.tolist())\n",
    "\n",
    "# Fit Model\n",
    "model.fit(train_em, train_label, epochs=4, validation_data=(test_em, test_label))\n",
    "\n",
    "eval_loss, eval_acc = model.evaluate(test_em, test_label)\n",
    "print('\\nEval loss: {:.3f}, Eval accuracy: {:.3f}'.format(eval_loss, eval_acc))\n",
    "\n",
    "pred = model.predict(test_em).argmax(axis=-1)\n",
    "\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(df['code'][2500:3500].tolist(), pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbwN0-7LF7Bz"
   },
   "source": [
    "# Distillibert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "zURKzB5xGcuJ",
    "outputId": "8e07a3b4-9e9c-4db1-e8c0-6c5d918115bd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4puT8zYF-JC"
   },
   "outputs": [],
   "source": [
    "batch_1 = df[:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "bFBBCNKqGLZ6",
    "outputId": "f555513e-af6a-42ab-cd67-ae168b30ba97"
   },
   "outputs": [],
   "source": [
    "batch_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "mGqRLvAoGP1Z",
    "outputId": "573160f5-41b0-493e-a2ac-b60a14c7e430"
   },
   "outputs": [],
   "source": [
    "batch_1['code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHXx0aNHGWgD"
   },
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SciBert\n",
    "scibert_model = BertModel.from_pretrained(\"allenai/scibert_scivocab_uncased\",\n",
    "                                  output_hidden_states=True)\n",
    "scibert_tokenizer = BertTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "\n",
    "print('scibert_tokenizer is type:', type(scibert_tokenizer))\n",
    "print('    scibert_model is type:', type(scibert_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNoUftJWGk3X"
   },
   "outputs": [],
   "source": [
    "tokenized = batch_1['sentence'].apply((lambda x: scibert_tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUsw4RkcGqjz"
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "S2p-5rpCGuBF",
    "outputId": "9343d5cc-fba7-4a3c-bf92-d999f0b5d8a3"
   },
   "outputs": [],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "s_QdfLjyGxE-",
    "outputId": "e52c2033-ed09-41ff-e0e9-383851a28246"
   },
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')     # Default CUDA devicecuda0\n",
    "cuda0 = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLKSC1HIGzPg"
   },
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)\n",
    "# input_ids = input_ids.to(cuda0)\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "# attention_mask = attention_mask.to(cuda0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    features = scibert_model(input_ids, attention_mask=attention_mask)[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CG_B3isIG126"
   },
   "outputs": [],
   "source": [
    "features = last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CA7QIMTtG5BX"
   },
   "outputs": [],
   "source": [
    "labels = batch_1['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eq278mmcG7wa"
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "9t_63xgWLYzZ",
    "outputId": "49ed4263-c4ca-4713-ad09-039bdc922158"
   },
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "OX9JI2LLLxVA",
    "outputId": "be986158-3fed-4374-ce30-6d85874b030f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "lr_clf = KNeighborsClassifier()\n",
    "lr_clf.fit(df['scibert'][:1000].tolist(), df['code'][:1000].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "U-DZTNEoM5nv",
    "outputId": "da515d44-5854-4c1e-bf5d-d9445643c0f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.738"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(df['scibert'][1000:2000].tolist(), df['code'][1000:2000].tolist())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pubmed_20k_Pandas.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
