{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Kcl0YURr1yHO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg9vHsH0pn_U"
   },
   "source": [
    "# Import and Preprocess/Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6aFAYwJFHPwp"
   },
   "outputs": [],
   "source": [
    "# Function which does everything below at once\n",
    "def open_format_data(filename):\n",
    "  # Save data from txt into list\n",
    "  f = open(filename, \"r\")\n",
    "\n",
    "  list_data = []\n",
    "  for x in f:\n",
    "      list_data.append(f.readline().rstrip().split(\"\\t\"))\n",
    "\n",
    "  # Load list into dataframe\n",
    "  column_names = ['label', \"sentence\"]\n",
    "  df = pd.DataFrame(list_data, columns= column_names)\n",
    "  df.head(10)\n",
    "\n",
    "  # Drop any null values\n",
    "  df = df.dropna()\n",
    "\n",
    "  # Drop duplicates\n",
    "  df = df.drop_duplicates()\n",
    "\n",
    "  # Append number representing label as code\n",
    "  df.label = pd.Categorical(df.label)\n",
    "  df['code'] = df.label.cat.codes\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qyP98KpnHvv0"
   },
   "outputs": [],
   "source": [
    "df = open_format_data(\"train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTvVH5UyHsTX"
   },
   "outputs": [],
   "source": [
    "# Save data from txt into list\n",
    "f = open(\"/content/drive/My Drive/Griffith/Data Mining/train.txt\", \"r\")\n",
    "\n",
    "list_data = []\n",
    "for x in f:\n",
    "    list_data.append(f.readline().rstrip().split(\"\\t\"))\n",
    "\n",
    "print(list_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "ddlcuFZy2Sg0",
    "outputId": "e15c2ce5-35e4-4d71-ed85-52e0f4fa361d"
   },
   "outputs": [],
   "source": [
    "# Load list into dataframe\n",
    "column_names = ['label', \"sentence\"]\n",
    "df = pd.DataFrame(list_data, columns= column_names)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "bCrHecKv2T6G",
    "outputId": "82cdc603-84f2-4bfd-85e5-5b32e2e7e8d7"
   },
   "outputs": [],
   "source": [
    "# Count all null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "0tcXakJo2WJA",
    "outputId": "2e2cb3c1-f719-477a-89cf-d08edc5621f7"
   },
   "outputs": [],
   "source": [
    "# Drop any null values\n",
    "df = df.dropna()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "tz6IRB2X2Y1Z",
    "outputId": "be6a0df9-a8e3-4d76-c40f-f21fbed5a1dd"
   },
   "outputs": [],
   "source": [
    "# Detect duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "1CwPAgHx2Z7r",
    "outputId": "7aa74ead-b74c-4048-91e9-58b5e32c6268"
   },
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "TYiU8VB725XV",
    "outputId": "7ca850a4-3cfa-4ebe-f59b-1728132a94a1"
   },
   "outputs": [],
   "source": [
    "# Append number representing label as code\n",
    "df.label = pd.Categorical(df.label)\n",
    "df['code'] = df.label.cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0QiFmEMphvr"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "FiwPvz1bpy91",
    "outputId": "22af54a2-4c23-4801-9700-cbe23b8f9a37"
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "nIadEZxtqNDg",
    "outputId": "9ef35a7c-7ea5-428d-a80c-98059140eebc"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "2EIxdIgOkNiW",
    "outputId": "73d79ed3-a443-43e6-d368-f0b0a139345e"
   },
   "outputs": [],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "wBk2y4aeVnl_",
    "outputId": "8f55898b-2d00-48c9-ab3e-5e29e7c3e75d"
   },
   "outputs": [],
   "source": [
    "df.groupby(\"label\")['sentence'].count().plot.bar()\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ERuUgqEpX0I"
   },
   "source": [
    "# Tensorflow Data Formatting and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "ZtcKaqio4Yb5",
    "outputId": "1c9a94ac-5cbf-43e2-8910-2feafa346f7d"
   },
   "outputs": [],
   "source": [
    "# Load into tensorflow dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((df.sentence, df.code))\n",
    "for b in train_dataset.take(5):\n",
    "  print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "u41AF_t87Hsk",
    "outputId": "224f6c3b-ece9-4121-8f29-36f3a4c6f26c"
   },
   "outputs": [],
   "source": [
    "# Generate vocab\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "vocabulary_set = set()\n",
    "for text_tensor, _ in train_dataset:\n",
    "  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
    "  vocabulary_set.update(some_tokens)\n",
    "\n",
    "vocab_size = len(vocabulary_set)\n",
    "# Increase vocab size for padding value (0)\n",
    "vocab_size += 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4xx2yBD7gTJ"
   },
   "outputs": [],
   "source": [
    "# Setup encoder\n",
    "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)\n",
    "\n",
    "def encode(text_tensor, label):\n",
    "  encoded_text = encoder.encode(text_tensor.numpy())\n",
    "  return encoded_text, label\n",
    "\n",
    "def encode_map_fn(text, label):\n",
    "  # py_func doesn't set the shape of the returned tensors.\n",
    "  encoded_text, label = tf.py_function(encode, \n",
    "                                       inp=[text, label], \n",
    "                                       Tout=(tf.int64, tf.int8))\n",
    "\n",
    "  # `tf.data.Datasets` work best if all components have a shape set\n",
    "  #  so set the shapes manually: \n",
    "  encoded_text.set_shape([None])\n",
    "  label.set_shape([])\n",
    "\n",
    "  return encoded_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "Gn5PgB2UolOg",
    "outputId": "e211010d-1bb0-4562-f54e-5cc940175277"
   },
   "outputs": [],
   "source": [
    "example_text = next(iter(train_dataset))[0].numpy()\n",
    "example_text = next(iter(train_dataset))[0].numpy()\n",
    "print(example_text)\n",
    "encoded_example = encoder.encode(example_text)\n",
    "print(encoded_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "5QJuPtEL7loC",
    "outputId": "6e404f47-2ca9-45e7-c9b6-f70f1ceca3b7"
   },
   "outputs": [],
   "source": [
    "# Encode sentences\n",
    "all_encoded_data = train_dataset.map(encode_map_fn)\n",
    "for ex in all_encoded_data.take(5):\n",
    "  print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_-4yjieB-7F"
   },
   "outputs": [],
   "source": [
    "# Shuffle into train/test data and add \n",
    "BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 64\n",
    "TAKE_SIZE = 2000\n",
    "\n",
    "train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\n",
    "train_data = train_data.padded_batch(BATCH_SIZE)\n",
    "\n",
    "test_data = all_encoded_data.take(TAKE_SIZE)\n",
    "test_data = test_data.padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "Kfe1yIAUCxnA",
    "outputId": "e9560bf0-f880-41ab-8d87-64de18ff2d11"
   },
   "outputs": [],
   "source": [
    "sample_text, sample_labels = next(iter(train_data))\n",
    "\n",
    "sample_text[0], encoder.decode(sample_text[0].numpy()), sample_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jIPas-ktM7Q"
   },
   "source": [
    "# Tensorflow Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "zZNCRVQjC7zX",
    "outputId": "b26b2b04-93ec-43f0-8f7a-c536cb1f6231"
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, 64))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
    "\n",
    "# One or more dense layers.\n",
    "# Edit the list in the `for` line to experiment with layer sizes.\n",
    "for units in [64, 64]:\n",
    "  model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "\n",
    "# Output layer. The first argument is the number of labels.\n",
    "model.add(tf.keras.layers.Dense(5))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "YLyHFC9uElSp",
    "outputId": "4fcdf5dd-13a4-46ca-d108-b3f736d35d3e"
   },
   "outputs": [],
   "source": [
    "model.fit(train_data, epochs=3, validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEht5nKQE1N1"
   },
   "outputs": [],
   "source": [
    "eval_loss, eval_acc = model.evaluate(test_data)\n",
    "\n",
    "print('\\nEval loss: {:.3f}, Eval accuracy: {:.3f}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBS-AG2BtVwV"
   },
   "source": [
    "# Tensorflow Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "tEJ5-CL0tYQw",
    "outputId": "2da6b012-c592-4ae9-878f-7842dbb71618"
   },
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(1000, 5)\n",
    "result = embedding_layer(tf.constant([1,2,3]))\n",
    "result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "Fy8fAq1Runpu",
    "outputId": "acf37ef9-c0b2-4982-bf19-537473e20440"
   },
   "outputs": [],
   "source": [
    "embedding_dim=16\n",
    "\n",
    "model = keras.Sequential([\n",
    "  layers.Embedding(vocab_size, embedding_dim),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  # layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(5)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "N4JZBdrauwia",
    "outputId": "6411e144-6fba-4a11-c12b-f4aa239f75b0"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=3,\n",
    "    validation_data=test_data, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "SI1vWUD4zOm7",
    "outputId": "0814cf37-3200-456a-b223-bebcda916de9"
   },
   "outputs": [],
   "source": [
    "# Retrive the learned embeddings\n",
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)\n",
    "\n",
    "# Save to disk\n",
    "import io\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for num, word in enumerate(encoder.tokens):\n",
    "  vec = weights[num+1] # skip 0, it's padding.\n",
    "  out_m.write(word + \"\\n\")\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()\n",
    "\n",
    "# Download to PC\n",
    "try:\n",
    "  from google.colab import files\n",
    "except ImportError:\n",
    "   pass\n",
    "else:\n",
    "  files.download('vecs.tsv')\n",
    "  files.download('meta.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF4bB9HVCGGR"
   },
   "source": [
    "# SciBERT Model For Sentence Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "tEWpbCTNCJbp",
    "outputId": "49109daa-5430-4f7d-f07e-ee3b5bfdb486"
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "QyIfIV1jCV9B",
    "outputId": "43b93ee8-ff1e-4f30-da57-cb1a894721cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scibert_tokenizer is type: <class 'transformers.tokenization_bert.BertTokenizer'>\n",
      "    scibert_model is type: <class 'transformers.modeling_bert.BertModel'>\n"
     ]
    }
   ],
   "source": [
    "scibert_model = BertModel.from_pretrained(\"allenai/scibert_scivocab_uncased\",\n",
    "                                  output_hidden_states=True)\n",
    "scibert_tokenizer = BertTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "\n",
    "print('scibert_tokenizer is type:', type(scibert_tokenizer))\n",
    "print('    scibert_model is type:', type(scibert_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Xk6zdIL6CapG"
   },
   "outputs": [],
   "source": [
    "def get_word_indeces(tokenizer, text, word):\n",
    "    '''\n",
    "    Determines the index or indeces of the tokens corresponding to `word`\n",
    "    within `text`. `word` can consist of multiple words, e.g., \"cell biology\".\n",
    "    \n",
    "    Determining the indeces is tricky because words can be broken into multiple\n",
    "    tokens. I've solved this with a rather roundabout approach--I replace `word`\n",
    "    with the correct number of `[MASK]` tokens, and then find these in the \n",
    "    tokenized result. \n",
    "    '''\n",
    "    # Tokenize the 'word'--it may be broken into multiple tokens or subwords.\n",
    "    word_tokens = tokenizer.tokenize(word)\n",
    "\n",
    "    # Create a sequence of `[MASK]` tokens to put in place of `word`.\n",
    "    masks_str = ' '.join(['[MASK]']*len(word_tokens))\n",
    "\n",
    "    # Replace the word with mask tokens.\n",
    "    text_masked = text.replace(word, masks_str)\n",
    "\n",
    "    # `encode` performs multiple functions:\n",
    "    #   1. Tokenizes the text\n",
    "    #   2. Maps the tokens to their IDs\n",
    "    #   3. Adds the special [CLS] and [SEP] tokens.\n",
    "    input_ids = tokenizer.encode(text_masked)\n",
    "\n",
    "    # Use numpy's `where` function to find all indeces of the [MASK] token.\n",
    "    mask_token_indeces = np.where(np.array(input_ids) == tokenizer.mask_token_id)[0]\n",
    "\n",
    "    return mask_token_indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ug_GZMKjFnIK"
   },
   "outputs": [],
   "source": [
    "def get_embedding(b_model, b_tokenizer, text):\n",
    "    '''\n",
    "    Uses the provided model and tokenizer to produce an embedding for the\n",
    "    provided `text`\n",
    "    '''\n",
    "\n",
    "    # Encode the text, adding the (required!) special tokens, and converting to\n",
    "    # PyTorch tensors.\n",
    "    encoded_dict = b_tokenizer.encode_plus(\n",
    "                        text,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                )\n",
    "\n",
    "    input_ids = encoded_dict['input_ids']\n",
    "    \n",
    "    b_model.eval()\n",
    "\n",
    "    # Run the text through the model and get the hidden states.\n",
    "    bert_outputs = b_model(input_ids)\n",
    "    \n",
    "    # Run the text through BERT, and collect all of the hidden states produced\n",
    "    # from all 12 layers. \n",
    "    with torch.no_grad():\n",
    "\n",
    "        outputs = b_model(input_ids)\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    # `hidden_states` has shape [13 x 1 x <sentence length> x 768]\n",
    "\n",
    "    # Select the embeddings from the second to last layer.\n",
    "    # `token_vecs` is a tensor with shape [<sent length> x 768]\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "\n",
    "    # Calculate the average of all token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "\n",
    "    # Convert to numpy array.\n",
    "    sentence_embedding = sentence_embedding.detach().numpy()\n",
    "\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "ujuY_wU_Fp_R",
    "outputId": "1613754a-e5de-40f1-b3e8-a26e5d7ae37c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding sizes:\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "text = \"hydrogels are hydrophilic polymer networks which may absorb from 10â€“20% (an arbitrary lower limit) up to thousands of times their dry weight in water.\"\n",
    "\n",
    "# Get the embedding for the sentence, as well as an embedding for 'hydrogels'.\n",
    "sen_emb = get_embedding(scibert_model, scibert_tokenizer, text)\n",
    "\n",
    "print('Embedding sizes:')\n",
    "print(sen_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tyLDA81MCk2"
   },
   "source": [
    "Look into using TF cause this is slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "4WL7iwzGKVHX",
    "outputId": "a9c2aadb-f3c8-4343-ee30-fbf9a19d0549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88797 88797\n",
      "139.64\n",
      "88797\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import timeit\n",
    "\n",
    "embeddings = []\n",
    "length = len(df['sentence'].tolist())\n",
    "index = 0\n",
    "\n",
    "start = timeit.default_timer()\n",
    "for sentence in df['sentence'].tolist():\n",
    "    clear_output(wait=True)\n",
    "    index += 1\n",
    "    sen_emb = get_embedding(scibert_model, scibert_tokenizer, sentence)\n",
    "    embeddings.append(sen_emb)\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    if (index/length*100) < 1:\n",
    "        expected_time = \"Calculating...\"\n",
    "\n",
    "    else:\n",
    "        time_perc = timeit.default_timer()\n",
    "        expected_time = np.round( (time_perc-start) /(index/length) /60,2)\n",
    "\n",
    "    print(index, length)\n",
    "    print(expected_time)\n",
    "\n",
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PmZkrrRX_CGP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>To investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Secondary outcome measures included the Wester...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>There was a clinically relevant reduction in t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Further , there was a clinically relevant redu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           sentence  code\n",
       "0  OBJECTIVE  To investigate the efficacy of @ weeks of dail...     3\n",
       "1    METHODS  Outcome measures included pain reduction and i...     2\n",
       "2    METHODS  Secondary outcome measures included the Wester...     2\n",
       "3    RESULTS  There was a clinically relevant reduction in t...     4\n",
       "4    RESULTS  Further , there was a clinically relevant redu...     4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LXAjeF4U-ydM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>code</th>\n",
       "      <th>scibert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>To investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.44510403, -0.31423956, -0.45745727, 0.4200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.4775299, -0.46893463, -0.22414015, 0.22520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Secondary outcome measures included the Wester...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.61925375, -0.19193889, -0.38404435, 0.2082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>There was a clinically relevant reduction in t...</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.5922383, -0.41908544, -0.33248687, 0.55146...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Further , there was a clinically relevant redu...</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.38201377, -0.53494513, 0.1772025, 0.381558...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           sentence  code  \\\n",
       "0  OBJECTIVE  To investigate the efficacy of @ weeks of dail...     3   \n",
       "1    METHODS  Outcome measures included pain reduction and i...     2   \n",
       "2    METHODS  Secondary outcome measures included the Wester...     2   \n",
       "3    RESULTS  There was a clinically relevant reduction in t...     4   \n",
       "4    RESULTS  Further , there was a clinically relevant redu...     4   \n",
       "\n",
       "                                             scibert  \n",
       "0  [-0.44510403, -0.31423956, -0.45745727, 0.4200...  \n",
       "1  [-0.4775299, -0.46893463, -0.22414015, 0.22520...  \n",
       "2  [-0.61925375, -0.19193889, -0.38404435, 0.2082...  \n",
       "3  [-0.5922383, -0.41908544, -0.33248687, 0.55146...  \n",
       "4  [-0.38201377, -0.53494513, 0.1772025, 0.381558...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['scibert'] = embeddings\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Y7kcDqCn_GnI"
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"./df_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating SciBert Embedded Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>code</th>\n",
       "      <th>scibert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>To investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.44510403, -0.31423956, -0.45745727, 0.4200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.4775299, -0.46893463, -0.22414015, 0.22520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Secondary outcome measures included the Wester...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.61925375, -0.19193889, -0.38404435, 0.2082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>There was a clinically relevant reduction in t...</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.5922383, -0.41908544, -0.33248687, 0.55146...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Further , there was a clinically relevant redu...</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.38201377, -0.53494513, 0.1772025, 0.381558...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           sentence  code  \\\n",
       "0  OBJECTIVE  To investigate the efficacy of @ weeks of dail...     3   \n",
       "1    METHODS  Outcome measures included pain reduction and i...     2   \n",
       "2    METHODS  Secondary outcome measures included the Wester...     2   \n",
       "3    RESULTS  There was a clinically relevant reduction in t...     4   \n",
       "4    RESULTS  Further , there was a clinically relevant redu...     4   \n",
       "\n",
       "                                             scibert  \n",
       "0  [-0.44510403, -0.31423956, -0.45745727, 0.4200...  \n",
       "1  [-0.4775299, -0.46893463, -0.22414015, 0.22520...  \n",
       "2  [-0.61925375, -0.19193889, -0.38404435, 0.2082...  \n",
       "3  [-0.5922383, -0.41908544, -0.33248687, 0.55146...  \n",
       "4  [-0.38201377, -0.53494513, 0.1772025, 0.381558...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "df = pd.read_pickle(\"./df_embeddings.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to weka\n",
    "export_df = df.drop(['label', 'sentence'], axis=1)\n",
    "\n",
    "def f(x):\n",
    "    return x.tolist()\n",
    "\n",
    "export_df['scibert'] = export_df['scibert'].map(f)\n",
    "\n",
    "print(export_df.values)\n",
    "\n",
    "import arff\n",
    "arff.dump('filename.arff'\n",
    "      , export_df.values\n",
    "      , relation='relation name'\n",
    "      , names=['code', 'scibert'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>code</th>\n",
       "      <th>scibert</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BACKGROUND</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONCLUSIONS</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>METHODS</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBJECTIVE</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESULTS</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentence  code  scibert\n",
       "label                               \n",
       "BACKGROUND        500   500      500\n",
       "CONCLUSIONS       500   500      500\n",
       "METHODS           500   500      500\n",
       "OBJECTIVE         500   500      500\n",
       "RESULTS           500   500      500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample even number from each class\n",
    "even_df = df.groupby('code').apply(lambda x: x.sample(n=500)).reset_index(drop = True)\n",
    "even_df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.6819527403960083\n",
      "0.654013853094385\n",
      "MCC\n",
      "0.700766156771334\n",
      "0.652233775495782\n",
      "Accuracy\n",
      "0.778\n",
      "0.733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model_even = KNeighborsClassifier()\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.6681035538397584\n",
      "0.6709305896250097\n",
      "MCC\n",
      "0.6634952331940656\n",
      "0.6558606143364742\n",
      "Accuracy\n",
      "0.747\n",
      "0.741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB()\n",
    "model_even = BernoulliNB()\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.6969765214942665\n",
      "0.680103550567688\n",
      "MCC\n",
      "0.6918251118653097\n",
      "0.6686883947774092\n",
      "Accuracy\n",
      "0.767\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model_even = GaussianNB()\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.46094697692739006\n",
      "0.4676075892099999\n",
      "MCC\n",
      "0.4103338396416756\n",
      "0.38655254976388786\n",
      "Accuracy\n",
      "0.559\n",
      "0.525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model_even = DecisionTreeClassifier()\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/connor/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.6931498071426793\n",
      "0.6671190236890402\n",
      "MCC\n",
      "0.7125171448205804\n",
      "0.6789894636994003\n",
      "Accuracy\n",
      "0.787\n",
      "0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/connor/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC(multi_class=\"ovr\", max_iter=1000)\n",
    "model_even = LinearSVC(multi_class=\"ovr\", max_iter=1000)\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.742674548713269\n",
      "0.7522561109618942\n",
      "MCC\n",
      "0.7866132899786072\n",
      "[[ 89   8  12  16   2]\n",
      " [ 20 117   5   0  17]\n",
      " [  4   2 324   2   8]\n",
      " [ 31   5   7  22   1]\n",
      " [  0   5  13   0 290]]\n",
      "0.757602626006683\n",
      "Accuracy\n",
      "0.842\n",
      "0.819\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='rbf', gamma=0.02, C=2)\n",
    "# model_even = SVC()\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "# model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "# pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(confusion_matrix(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.7231861816607512\n",
      "0.7153398986547954\n",
      "MCC\n",
      "0.7527761095624504\n",
      "0.7345170631965806\n",
      "Accuracy\n",
      "0.817\n",
      "0.802\n",
      "[[ 71  16   3  32   5]\n",
      " [ 16 113   3  10  17]\n",
      " [ 13   0 309   5  13]\n",
      " [ 19   6   5  35   1]\n",
      " [  1  14  18   1 274]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(multi_class=\"ovr\", max_iter=1000)\n",
    "model_even = LogisticRegression(multi_class=\"ovr\", max_iter=1000)\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(confusion_matrix(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.7058321377086436\n",
      "0.7256700391541749\n",
      "MCC\n",
      "0.7370274149726393\n",
      "0.7448034226562301\n",
      "Accuracy\n",
      "0.805\n",
      "0.809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier()\n",
    "model_even = MLPClassifier()\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.6976264130136529\n",
      "0.7122919005635008\n",
      "MCC\n",
      "0.7286235564447606\n",
      "0.7298053612649003\n",
      "Accuracy\n",
      "0.798\n",
      "0.799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "model = Perceptron()\n",
    "model_even = Perceptron()\n",
    "# Fit models\n",
    "model.fit(df['scibert'][:2500].tolist(), df['code'][:2500].tolist())\n",
    "model_even.fit(even_df['scibert'].tolist(), even_df['code'].tolist())\n",
    "# Predictions for each model\n",
    "pred = model.predict(df['scibert'][2500:3500].tolist())\n",
    "pred_even = model_even.predict(df['scibert'][2500:3500].tolist())\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred_even, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred_even))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 0.7245 - accuracy: 0.7280 - val_loss: 0.5772 - val_accuracy: 0.8020\n",
      "Epoch 2/4\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.4701 - accuracy: 0.8300 - val_loss: 0.5675 - val_accuracy: 0.8090\n",
      "Epoch 3/4\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.3893 - accuracy: 0.8580 - val_loss: 0.6605 - val_accuracy: 0.7610\n",
      "Epoch 4/4\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 0.3543 - accuracy: 0.8656 - val_loss: 0.5173 - val_accuracy: 0.8220\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.8220\n",
      "\n",
      "Eval loss: 0.517, Eval accuracy: 0.822\n",
      "F1 Score\n",
      "0.7312273609053561\n",
      "MCC\n",
      "0.7599122337675305\n",
      "Accuracy\n",
      "0.822\n",
      "Confusion Matrix\n",
      "[[ 86  12   9  16   4]\n",
      " [ 21 111   5   3  19]\n",
      " [ 10   1 319   3   7]\n",
      " [ 29   5   5  26   1]\n",
      " [  0   7  21   0 280]]\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow NN\n",
    "import numpy as np\n",
    "\n",
    "# Build model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(768, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Output layer. The first argument is the number of labels.\n",
    "model.add(tf.keras.layers.Dense(5))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "train_em = df['scibert'][:2500]\n",
    "train_em = np.array(train_em.tolist())\n",
    "train_label = df['code'][:2500]\n",
    "train_label = np.array(train_label.tolist())\n",
    "\n",
    "test_em = df['scibert'][2500:3500]\n",
    "test_em = np.array(test_em.tolist())\n",
    "test_label = df['code'][2500:3500]\n",
    "test_label = np.array(test_label.tolist())\n",
    "\n",
    "# Fit Model\n",
    "model.fit(train_em, train_label, epochs=4, validation_data=(test_em, test_label))\n",
    "\n",
    "eval_loss, eval_acc = model.evaluate(test_em, test_label)\n",
    "print('\\nEval loss: {:.3f}, Eval accuracy: {:.3f}'.format(eval_loss, eval_acc))\n",
    "\n",
    "pred = model.predict(test_em).argmax(axis=-1)\n",
    "\n",
    "# Evaluate\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(df['code'][2500:3500].tolist(), pred, average=\"macro\"))\n",
    "print(\"MCC\")\n",
    "print(matthews_corrcoef(df['code'][2500:3500].tolist(), pred))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(df['code'][2500:3500].tolist(), pred))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(df['code'][2500:3500].tolist(), pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbwN0-7LF7Bz"
   },
   "source": [
    "# Distillibert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "zURKzB5xGcuJ",
    "outputId": "8e07a3b4-9e9c-4db1-e8c0-6c5d918115bd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4puT8zYF-JC"
   },
   "outputs": [],
   "source": [
    "batch_1 = df[:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "bFBBCNKqGLZ6",
    "outputId": "f555513e-af6a-42ab-cd67-ae168b30ba97"
   },
   "outputs": [],
   "source": [
    "batch_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "mGqRLvAoGP1Z",
    "outputId": "573160f5-41b0-493e-a2ac-b60a14c7e430"
   },
   "outputs": [],
   "source": [
    "batch_1['code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHXx0aNHGWgD"
   },
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SciBert\n",
    "scibert_model = BertModel.from_pretrained(\"allenai/scibert_scivocab_uncased\",\n",
    "                                  output_hidden_states=True)\n",
    "scibert_tokenizer = BertTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "\n",
    "print('scibert_tokenizer is type:', type(scibert_tokenizer))\n",
    "print('    scibert_model is type:', type(scibert_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNoUftJWGk3X"
   },
   "outputs": [],
   "source": [
    "tokenized = batch_1['sentence'].apply((lambda x: scibert_tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUsw4RkcGqjz"
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "S2p-5rpCGuBF",
    "outputId": "9343d5cc-fba7-4a3c-bf92-d999f0b5d8a3"
   },
   "outputs": [],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "s_QdfLjyGxE-",
    "outputId": "e52c2033-ed09-41ff-e0e9-383851a28246"
   },
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')     # Default CUDA devicecuda0\n",
    "cuda0 = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLKSC1HIGzPg"
   },
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)\n",
    "# input_ids = input_ids.to(cuda0)\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "# attention_mask = attention_mask.to(cuda0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    features = scibert_model(input_ids, attention_mask=attention_mask)[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CG_B3isIG126"
   },
   "outputs": [],
   "source": [
    "features = last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CA7QIMTtG5BX"
   },
   "outputs": [],
   "source": [
    "labels = batch_1['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eq278mmcG7wa"
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "9t_63xgWLYzZ",
    "outputId": "49ed4263-c4ca-4713-ad09-039bdc922158"
   },
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "OX9JI2LLLxVA",
    "outputId": "be986158-3fed-4374-ce30-6d85874b030f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "lr_clf = KNeighborsClassifier()\n",
    "lr_clf.fit(df['scibert'][:1000].tolist(), df['code'][:1000].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "U-DZTNEoM5nv",
    "outputId": "da515d44-5854-4c1e-bf5d-d9445643c0f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.738"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(df['scibert'][1000:2000].tolist(), df['code'][1000:2000].tolist())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pubmed_20k_Pandas.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
